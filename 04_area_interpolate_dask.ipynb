{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f2586a-5b6a-4d46-b6e8-1991ae3bec6f",
   "metadata": {},
   "source": [
    "# (Distributed) areal interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f875bd-2714-4551-b10c-1ef3f514478d",
   "metadata": {},
   "source": [
    "In this notebook, we compare the single-core version in `tobler.area_weighted.area_interpolate` with the distributed version in `tobler.area_weighted.area_interpolate_dask`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4084f715-3989-4424-943a-2a4066a8bcf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '1'\n",
    "\n",
    "import pandas\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "import tobler\n",
    "from libpysal.examples import load_example\n",
    "import numpy as np\n",
    "\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a2e15-866b-407d-b65d-54a675aefbd7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080369e7-f3d4-41c6-a629-12ed458eb743",
   "metadata": {},
   "source": [
    "Load example data from `pysal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb395dc5-67f2-462e-a1cf-919c8e6d0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = load_example('Charleston1')\n",
    "c2 = load_example('Charleston2')\n",
    "\n",
    "crs = 6569  # https://epsg.io/6569\n",
    "\n",
    "tracts = geopandas.read_file(c1.get_path('sc_final_census2.shp')).to_crs(crs)\n",
    "zip_codes = geopandas.read_file(c2.get_path('CharlestonMSA2.shp')).to_crs(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11c1d7-6435-40cb-a4d4-851f63eccf01",
   "metadata": {},
   "source": [
    "We make up a categorical variable with four classes distributed randomly across the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3543702f-5e8a-4336-a14d-19a4eeb77b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "tracts['rando'] = pandas.Series(\n",
    "    rng.integers(0, 4, len(tracts)), dtype='category'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2546bb7-abcb-4cad-8db8-c569ea9289ae",
   "metadata": {},
   "source": [
    "We will set up a local Dask cluster so you can follow the computations on the dashboard (`http://localhost:8787` by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65ac8ec-51e2-4d2d-abb2-96a7519ed749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client(LocalCluster(n_workers=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c32c7d-0ca8-4945-a1f8-edfbc8917880",
   "metadata": {},
   "source": [
    "Finally, for Dask, we need to provide `dask_geopandas.GeoDataFrame` objects with spatial partitions and categorical variables properly set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31a1a91-4071-40e2-a21f-7e035d734976",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtracts = (\n",
    "    dask_geopandas.from_geopandas(tracts[['geometry', 'rando']], npartitions=4)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")\n",
    "\n",
    "dzips = (\n",
    "    dask_geopandas.from_geopandas(zip_codes[['ZIP', 'geometry']], npartitions=4)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f986ec-ea46-479e-aed8-5edeeaf16fda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**IMPORTANT** - At this point, only *categorical* variables are implemented, so those are what we will test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783aabc-8221-40f6-a0d5-bf21dd75e2a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dafb11-ec94-43c2-baec-2a5e2a0b380d",
   "metadata": {},
   "source": [
    "- Single core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4cde6d-73c1-4197-86ed-131724e21296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts, zip_codes, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982d8dc-c1e9-4927-8643-9900b1b09890",
   "metadata": {},
   "source": [
    "- Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c7896f-9004-4a07-b3ba-75301f8120e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts, dzips, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19b8dd-505f-4dc1-ba85-9fd825e59b43",
   "metadata": {},
   "source": [
    "And we can compare both results are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc830b2-99a7-4c11-a8d9-0fad3aefcf06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rando_0    4.188295e-08\n",
       "rando_1    5.328575e-08\n",
       "rando_2    5.396667e-08\n",
       "rando_3    2.935173e-08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (\n",
    "    cat_dk\n",
    "    .set_index('ZIP')\n",
    "    .reindex(zip_codes['ZIP'].values)\n",
    "    .drop(columns='geometry')\n",
    ")\n",
    "\n",
    "b = (\n",
    "    cat_sc\n",
    "    .drop(columns='geometry')\n",
    "    [['rando_0', 'rando_1', 'rando_2', 'rando_3']]\n",
    ")\n",
    "b.index = a.index\n",
    "\n",
    "(a - b).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e04df1-3331-449c-b74c-e910239c3067",
   "metadata": {},
   "source": [
    "The differences in the estimates for the proportions of each area start at the 8th decimal, and thus likely rounding errors derived from the different approaches used to compute the interpolation (the single core does it in one-shot, while Dask computes parts and brings them together later with a sum)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debbdf4-892f-4fda-834a-0403595794ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Performance\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE** - Timings below do _not_ include computation time required for spatial shuffling and partitioning (which can be substantial with large datasets), or converting from `geopandas`. These are \"sunk costs\" that'll only make this approach preferable with large datasets, although they can be computed once and the result stored in disk efficiently (e.g., as Parquet files). Having said that, when \"larger\" is large enough is not very large in modern terms: from a handful of thousand observations the gains will be substantial if several cores/workers are available.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5242c13-c4cd-46e2-9131-ec1734bcc142",
   "metadata": {},
   "source": [
    "We can now time the example above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "902e494b-65ba-4fa2-99e6-eb3a513769f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.5 ms ± 4.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts, zip_codes, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cfc44d9-f79a-4b8e-9caa-975ea64d5f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444 ms ± 2.69 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts, dzips, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124ee86-c527-4386-be8d-2dc833270fd9",
   "metadata": {},
   "source": [
    "This is notably slower (about 5x!). For such a small dataset, the overhead in distributing computations and collecting them overcomes any gains in parallelism.\n",
    "\n",
    "Now we can artificially increase the size of the datasets by concatenating them several times and re-computing (this time we only time one execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f56d579-0022-45c2-845c-f351bf96ed01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40x increase | N. tracts: 4680 | N. ZIPs: 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 30.18 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 30.17 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sizeup = 40\n",
    "tracts_lrg = pandas.concat([tracts] * sizeup)\n",
    "zips_lrg = pandas.concat([zip_codes] * sizeup)\n",
    "print(\n",
    "    f'{sizeup}x increase | N. tracts: {len(tracts_lrg)} | N. ZIPs: {len(zips_lrg)}'\n",
    ")\n",
    "\n",
    "dtracts_lrg = (\n",
    "    dask_geopandas.from_geopandas(tracts_lrg[['geometry', 'rando']], chunksize=800)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")\n",
    "\n",
    "dzips_lrg = (\n",
    "    dask_geopandas.from_geopandas(zips_lrg[['ZIP', 'geometry']], chunksize=800)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5187109-ba95-4b5f-b373-2ec4745d0289",
   "metadata": {},
   "source": [
    "And re-compute the timings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da372a-f791-47fb-ade0-317a1cf6ff9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "620cf9ab-7b9e-4458-809c-c7a73d13f26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 10x\n",
      "CPU times: user 7.21 s, sys: 11.3 ms, total: 7.23 s\n",
      "Wall time: 6.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c615b27a-e004-429b-a0c5-e4b237516f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 10x\n",
      "CPU times: user 548 ms, sys: 18 ms, total: 566 ms\n",
      "Wall time: 3.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc13af25-e97e-4b34-bb1f-bb946c15748e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 20x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dbb40d4-4b3b-446d-9d1b-99462a122d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 20x\n",
      "CPU times: user 28.6 s, sys: 26.1 ms, total: 28.7 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ca1394-5f8d-428f-a61c-87beb8778322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 20x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 16.77 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 65.3 ms, total: 1.38 s\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b34b4-9fea-48a6-b38b-8b1a5d755ca1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 30x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1598ce3f-d21e-4a60-9619-ee5b1eb4932f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 30x\n",
      "CPU times: user 1min 4s, sys: 176 ms, total: 1min 4s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224ffbca-7690-4b20-bad2-efbf042623a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 30x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 25.14 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 58.8 ms, total: 1.97 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004834f-c5ce-4f92-be9a-364a07c7996b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b9d06a-9034-4c39-b3a9-92fc6408d5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 40x\n",
      "CPU times: user 2min 2s, sys: 1.71 s, total: 2min 3s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a68e5fe-ee41-48cc-9222-6554a7651c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 40x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 33.52 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 417 ms, total: 5.99 s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93576191-ddb0-4316-af7e-d12393e520b6",
   "metadata": {},
   "source": [
    "## Bug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ff509-cd42-4982-8144-f4915e996f83",
   "metadata": {},
   "source": [
    "There is a recurrent bug that appears in some cases that errors the computation and should be fixed ideally before merging. The code below reproduces it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2470144-7c4d-4638-90a8-6bc4254128ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 11:19:01,747 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('aggregate-combine-827a5db528ee8de42db84a4c3d7fb9a7', 2, 1)\n",
      "Function:  pipe\n",
      "args:      ([      sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                                                 ...                                              \n",
      "29437                                            0  ...                                      0.000000\n",
      "29472                                            0  ...                                      0.000000\n",
      "29483                                            0  ...                                      0.008659\n",
      "\n",
      "[3 rows x 4 columns],        sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                                                  ...                                              \n",
      "29437                                           0.0  ...                                           0.0\n",
      "29472                                           0.0  ...                                           0.0\n",
      "29483                                           0.0  \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\\'can only concatenate str (not \"float\") to str\\')'\n",
      "\n",
      "2023-08-11 11:19:01,750 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('aggregate-combine-827a5db528ee8de42db84a4c3d7fb9a7', 0, 1)\n",
      "Function:  pipe\n",
      "args:      ([       sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                                                  ...                                              \n",
      "29438                                      0.905017  ...                                             0\n",
      "\n",
      "[1 rows x 4 columns],        sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                                                  ...                                              \n",
      "29449                                      0.001648  ...                                             0\n",
      "29426                                      0.000000  ...                                             0\n",
      "29414                                      0.000000  ...                                             0\n",
      "\n",
      "[3 rows x 4 columns],        sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                      \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\\'can only concatenate str (not \"float\") to str\\')'\n",
      "\n",
      "2023-08-11 11:19:01,761 - distributed.worker - ERROR - Exception during execution of task ('aggregate-combine-827a5db528ee8de42db84a4c3d7fb9a7', 4, 1).\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/buffer.py\", line 184, in __getitem__\n",
      "    return self.fast[key]\n",
      "           ~~~~~~~~~^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/common.py\", line 127, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/lru.py\", line 117, in __getitem__\n",
      "    result = self.d[key]\n",
      "             ~~~~~~^^^^^\n",
      "KeyError: \"('aggregate-chunk-827a5db528ee8de42db84a4c3d7fb9a7-1584b66fccc2ab7917ded8b6f5bb1127', 34)\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/worker.py\", line 2412, in _prepare_args_for_execution\n",
      "    data[k] = self.data[k]\n",
      "              ~~~~~~~~~^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/spill.py\", line 216, in __getitem__\n",
      "    return super().__getitem__(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/common.py\", line 127, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/buffer.py\", line 186, in __getitem__\n",
      "    return self.slow_to_fast(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/buffer.py\", line 153, in slow_to_fast\n",
      "    value = self.slow[key]\n",
      "            ~~~~~~~~~^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/common.py\", line 127, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/zict/cache.py\", line 67, in __getitem__\n",
      "    gen = self._last_updated[key]\n",
      "          ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "KeyError: \"('aggregate-chunk-827a5db528ee8de42db84a4c3d7fb9a7-1584b66fccc2ab7917ded8b6f5bb1127', 34)\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/worker.py\", line 2264, in execute\n",
      "    args2, kwargs2 = self._prepare_args_for_execution(ts, args, kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/worker.py\", line 2416, in _prepare_args_for_execution\n",
      "    data[k] = Actor(type(self.state.actors[k]), self.address, k, self)\n",
      "                         ~~~~~~~~~~~~~~~~~^^^\n",
      "KeyError: \"('aggregate-chunk-827a5db528ee8de42db84a4c3d7fb9a7-1584b66fccc2ab7917ded8b6f5bb1127', 34)\"\n",
      "2023-08-11 11:19:01,791 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('aggregate-combine-827a5db528ee8de42db84a4c3d7fb9a7', 3, 1)\n",
      "Function:  pipe\n",
      "args:      ([       sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                                                  ...                                              \n",
      "29487                                      0.002037  ...                                             0\n",
      "29455                                      0.275390  ...                                             0\n",
      "\n",
      "[2 rows x 4 columns],        sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                                                  ...                                              \n",
      "29487                                      0.000000  ...                                      0.000000\n",
      "29455                                      0.002053  ...                                      0.018981\n",
      "\n",
      "[2 rows x 4 columns],        sum-rando_0-17eccfbe7bc44d26fa589319100d6357  ...  sum-rando_3-52ec0a920e05152510b5ff7aa35c0200\n",
      "ZIP                      \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\\'can only concatenate str (not \"float\") to str\\')'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m dtracts \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     dask_geopandas\u001b[38;5;241m.\u001b[39mfrom_geopandas(tracts[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrando\u001b[39m\u001b[38;5;124m'\u001b[39m]], npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mspatial_shuffle(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhilbert\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m dzips \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m     dask_geopandas\u001b[38;5;241m.\u001b[39mfrom_geopandas(zip_codes[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZIP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]], npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mspatial_shuffle(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhilbert\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m cat_dk \u001b[38;5;241m=\u001b[39m \u001b[43mtobler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marea_weighted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marea_interpolate_dask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtracts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdzips\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZIP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrando\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m---> 13\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tobler/lib/python3.11/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/tobler/lib/python3.11/site-packages/dask/dataframe/groupby.py:1209\u001b[0m, in \u001b[0;36m_groupby_apply_funcs\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1207\u001b[0m result \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result_column, func, func_kwargs \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m-> 1209\u001b[0m     r \u001b[38;5;241m=\u001b[39m func(grouped, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(r):\n",
      "File \u001b[0;32m/opt/conda/envs/tobler/lib/python3.11/site-packages/dask/dataframe/groupby.py:1255\u001b[0m, in \u001b[0;36m_apply_func_to_column\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(df_like)\n\u001b[0;32m-> 1255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(df_like[column])\n",
      "File \u001b[0;32m/opt/conda/envs/tobler/lib/python3.11/site-packages/pandas/_libs/groupby.pyx:717\u001b[0m, in \u001b[0;36mpandas._libs.groupby.group_sum\u001b[0;34m()\u001b[0m\n\u001b[1;32m    715\u001b[0m     t = val\n\u001b[1;32m    716\u001b[0m else:\n\u001b[0;32m--> 717\u001b[0m     t = sumx[lab, j] + val\n\u001b[1;32m    718\u001b[0m sumx[lab, j] = t\n\u001b[1;32m    719\u001b[0m \n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "dtracts = (\n",
    "    dask_geopandas.from_geopandas(tracts[['geometry', 'rando']], npartitions=16)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")\n",
    "\n",
    "dzips = (\n",
    "    dask_geopandas.from_geopandas(zip_codes[['ZIP', 'geometry']], npartitions=16)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")\n",
    "\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts, dzips, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08596315-236b-45df-955e-44a98b0a2eba",
   "metadata": {},
   "source": [
    "[DAB]: my hunch is that the error, though cryptic and hard to debug, comes from a worker returning an empty result (perhaps `None`?) which, when it's passed through the aggregation post collection from the workers, raises the error. Further investigation is warranted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobler",
   "language": "python",
   "name": "tobler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
